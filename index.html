
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">

<head>

  <title>Yizhe Xiong's Homepage</title>

  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta name="description" content="Yizhe Xiong is currently a Ph.D. candidate at School of Software, Tsinghua University.">
  <meta name="keywords" content="Yizhe Xiong, 熊翊哲, xiongyizhe, Yizhe, Xiong, Deep Learning, Tsinghua, THU, Computer, Vision, Transfer">
  <meta name="author" content="Yizhe Xiong" />

  <link rel="stylesheet" href="w3.css">

  <style>
  .w3-sidebar a {font-family: "Roboto", sans-serif}
  body,h1,h2,h3,h4,h5,h6,.w3-wide {font-family: "Montserrat", sans-serif;}
  </style>

  <link rel="icon" type="image/jpg" href="images/timg.jpg">
  <!-- TODO: icons.png image change. -->
  <!--
  <script src="jquery.min.js"></script>
  <script>
  $(document).ready(function(){
    // Add smooth scrolling to all links
    $("a").on('click', function(event) {
      // Make sure this.hash has a value before overriding default behavior
      if (this.hash !== "") {
        // Prevent default anchor click behavior
        event.preventDefault();
        // Store hash
        var hash = this.hash;
        // Using jQuery's animate() method to add smooth page scroll
        // The optional number (800) specifies the number of milliseconds it takes to scroll to the specified area
        $('html, body').animate({
          scrollTop: $(hash).offset().top
        }, 800, function(){
          // Add hash (#) to URL when done scrolling (default click behavior)
          window.location.hash = hash;
        });
      } // End if
    });
  });
  </script>
  //-->

</head>


<body class="w3-content" style="max-width:1000px">

<!-- Sidebar/menu -->
<nav class="w3-sidebar w3-bar-block w3-black w3-collapse w3-top w3-right" style="z-index:3;width:150px" id="mySidebar">
  <div class="w3-container w3-display-container w3-padding-16">
    <h3><b>YIZHE</b></h3>
  </div>
  <div class="w3-padding-64 w3-text-light-grey w3-large" style="font-weight:bold">
    <a href="#home" class="w3-bar-item w3-button">Home</a>
    <a href="#news" class="w3-bar-item w3-button">News</a>
    <a href="#publications" class="w3-bar-item w3-button">Research</a>
    <a href="#service" class="w3-bar-item w3-button">Service</a>
    <a href="#award" class="w3-bar-item w3-button">Awards</a>
  </div>
</nav>

<!-- Top menu on small screens -->
<header class="w3-bar w3-top w3-hide-large w3-black w3-xlarge">
  <div class="w3-bar-item w3-padding-24">YIZHE</div>
  <a href="javascript:void(0)" class="w3-bar-item w3-button w3-padding-24 w3-right"  style="font-stretch: extra-expanded;" onclick="w3_open()"><b>≡</b></a>
  </div>
</header>

<!-- Overlay effect when opening sidebar on small screens -->
<div class="w3-overlay w3-hide-large" onclick="w3_close()" style="cursor:pointer" title="close side menu" id="myOverlay"></div>

<!-- !PAGE CONTENT! -->
<div class="w3-main" style="margin-left:150px">

  <!-- Push down content on small screens -->
  <div class="w3-hide-large" style="margin-top:83px"></div>

<!-- The Home Section -->
    <div class="w3-container w3-center w3-padding-32" id="home">
      <img style="width: 80%;max-width: 240px" alt="profile photo" src="images/yizhe_profile.jpg">
      <!-- TODO: make it a circle -->
      <h1>Yizhe Xiong (熊翊哲)</h1>
        <p class="w3-justify" style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;max-width:600px">
          I am now a Ph.D. candidate at <a href="http://ise.thss.tsinghua.edu.cn/mig/index.html">Multimedia Intelligence Group</a>, <a href="https://www.thss.tsinghua.edu.cn/">School of Software</a>, <a href="https://www.tsinghua.edu.cn/index.htm">Tsinghua University</a>. Before that, I received my bachelor's degree at <a href="https://www.cs.tsinghua.edu.cn/">Department of Computer Science and Technology</a>, <a href="https://www.tsinghua.edu.cn/index.htm">Tsinghua University</a>. I am instructed by <a href="https://scholar.google.com/citations?user=B7F3yt4AAAAJ&hl=en&oi=ao">Prof. Guiguang Ding</a>.
        </p>
        <p class="w3-center">
          <a href="mailto:xiongyizhe2001@163.com">Email</a> &nbsp/&nbsp
          <a href="https://scholar.google.com/citations?user=HptpkCYAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
          <a href="https://www.linkedin.com/in/bostoncake/">Linkedin</a> &nbsp/&nbsp
	  <a href="https://www.xiongyizhe.xyz/1210.pdf">CV</a>
          <!-- <a href="https://dblp.org/pid/63/8217-1.html"> DBLP </a> -->
        </p>
        </tbody></table>
  </div>

<!-- The News Section -->
  <div class="w3-container w3-light-grey w3-padding-32" id="news">
   <h2>News</h2>
      <!-- <p><li> <a style="color:red">05/2023, Haven't updated in about one year. Some nice work has been done recently, and I will try to update more frequently</a>.</li></p> -->
      <p><li> 12/2024, <a href="https://arxiv.org/abs/2404.17808">Scaffold-BPE</a> has been accepted by AAAI 2025.</li></p>
      <p><li> 12/2024, One article is accepted by COLING 2025.</li></p>
      <p><li> 07/2024, Our paper on PEFT has been accepted by ECCV 2024.</li></p>
      <p><li> 04/2024, We have made some novel explorations in the field of LLM pre-training. Checkout <a href="https://arxiv.org/abs/2404.17785">Temporal Scaling Law</a> and <a href="https://arxiv.org/abs/2404.17808">Scaffold-BPE</a> on arXiv.</li></p>
      <p><li> 03/2024, Checkout our latest work on <a href="https://arxiv.org/abs/2403.09192">fine-tuning & task adaptation</a>.</li></p>
      <p><li> 07/2023, Our paper on domain adaptation has been accepted by ICCV 2023.</li></p>

  </div>
<!-- The Projects Section -->
  <!-- <div class="w3-container w3-padding-32" id="projects">
    <h2>Recent Projects</h2>
    <p class="w3-justify">
        Actually, model compression is a kind of technique for developing portable deep neural networks with lower memory and computation costs. I have done several projects in Huawei including some smartphones' applications in 2019 and 2020 (e.g. Mate 30 and Honor V30). Currently, I am leading the AdderNet project, which aims to develop a series of deep learning models using only additions (<a href="https://www.reddit.com/r/MachineLearning/comments/ekw2s1/r_addernet_do_we_really_need_multiplications_in/">Discussions on Reddit</a>).
    </p>
	
	<h4><li>The Vanilla Neural Architecture for the 2020s</li></h4>
        <img style="width:96%;" src="images/VanillaNet.png"> 
        <p class="w3-justify">
        <a style="color: #447ec9" href="https://github.com/huawei-noah/VanillaNet">Project Page</a> | <a style="color: #447ec9" href="https://arxiv.org/abs/2305.12972">Paper</a> | <a style="color: #447ec9" href="https://www.zhihu.com/question/531529633/answer/3047230939">Discussion on Zhihu</a> 
        </p>
        <p class="w3-justify">
        <span style="color:red">VanillaNet is remarkable!</span> The concept was born from embracing the "less is more" philosophy in computer vision. It's elegantly designed by avoiding intricate depth and operations, such as self-attention, making it remarkably powerful yet concise. The 6-layer VanillaNet surpasses ResNet-34, and the 13-layer variant achieves about 83% Top-1 accuracy, outpacing the performance of networks with hundreds of layers, and revealing exceptional hardware efficiency advantages.
        </p> 
	 
        <h4><li>Adder Neural Networks</li></h4>
        <img style="width:96%;" src="images/AdderNet.jpg"> 
        <p class="w3-justify">
        <a style="color: #447ec9" href="https://github.com/huawei-noah/AdderNet">Project Page</a> | <a style="color: #447ec9" href="https://arxiv.org/pdf/2101.10015.pdf">Hardware Implementation</a>
        </p>
        <p class="w3-justify">
        I would like to say, <span style="color:red">AdderNet is very cool!</span> The initial idea was came up in about 2017 when climbing with some friends at Beijing. By replacing all convolutional layers (except the first and the last layers), we now can obtain comparable performance on ResNet architectures. In addition, to make the story more complete, we recent release the hardware implementation and some quantization methods. The results are quite encouraging, we can reduce both <strong>the energy consumption and thecircuit areas significantly without affecting the performance</strong>. Now, we are working on more applications to reduce the costs of launching AI algorithms such as low-level vision, detection, and NLP tasks.
        </p> 

        <h4><li>GhostNet on MindSpore: SOTA Lightweight CV Networks</li></h4>
        <img style="width:96%;" src="images/GhostNet.png"> 
        <p class="w3-justify">
        <a style="color: #447ec9" href="https://live.huawei.com/huaweiconnect/meeting/cn/5872.html">Huawei Connect (HC) 2020</a> | <a style="color: #447ec9" href="https://www.mindspore.cn/resources/hub">MindSpore Hub</a>
        </p>
        <p class="w3-justify">
        The initial verison of GhostNet was accepted by CVPR 2020, which achieved SOTA performance on ImageNet: <span style="color:red">75.7%</span> top1 acc with only <span style="color:red">226M FLOPS</span>. In the current version, we release a series computer vision models (e.g. int8 quantization, detection, and larger networks) on <strong>MindsSpore 1.0</strong> and <strong>Mate 30 Pro (Kirin 990)</strong>.
        </p> 

        <h4><li>AI on Ascend: Real-Time Video Style Transfer</li></h4>
        <img style="width:32%;" src="images/atlas200.png"> &nbsp&nbsp <img style="width:60%;" src="images/video.gif">
        <p class="w3-justify">
        <a style="color: #447ec9" href="https://www.huaweicloud.com/intl/en-us/HDC.Cloud.html">Huawei Developer Conference (HDC) 2020</a> | <a style="color: #447ec9" href="https://developer.huaweicloud.com/exhibition/Atlas_neural_style.html">Online Demo</a>
        </p>
        <p class="w3-justify">
        This project aims to develop a video style transfer system on the <strong>Huawei Atlas 200 DK AI developer Kit</strong>. The latency of the original model for processing one image is about <span style="color:red">630ms</span>. After accelerating it using our method, the lantency now is about <span style="color:red">40ms</span>. 
        </p>  

  </div> -->
  
  <!-- The Talks Section -->
  <!-- <div class="w3-container w3-light-grey w3-padding-32" id="talks">
    <h2>Talks</h2>
      <p><li> 12/2022, Hardware Efficient Deep Learning at <a href="https://ccf.org.cn/cncc2022/schedule_d_4179">China National Computer Congress (CNCC) 2022</a>. Thanks Prof. <a href="http://www.nlpr.ia.ac.cn/jcheng/">Jian Cheng</a> for the invitation.</li></p>
      <p><li> 05/2022, Low-Level Vision Transformer and Model Compression at <a href="https://2022.baai.ac.cn/">BAAI Conference 2022</a>. Thanks Prof. <a href="https://people.ucas.edu.cn/~sgshan?language=en">Shiguang Shan</a> for the invitation.</li></p>
      <p><li> 10/2021, Vision Transformer at <a href="http://valser.org/2021/#/tutorial">VALSE 2021 Tutorial</a>. Thanks Prof. <a href="https://people.ucas.edu.cn/~sgshan?language=en">Shiguang Shan</a> for the invitation.</li></p>
	  <p><li> 05/2021, Adder Neural Network at <a href="https://haet2021.github.io/speakers.html">HAET ICLR 2021 workshop</a>. Thanks <a href="https://datawisdom.ca/">Vahid Partovi Nia</a> for the invitation.</li></p>
      <p><li> 06/2020, "<a href="http://valser.org/webinar/slide/slides/20200603/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9-%E5%B7%A5%E4%B8%9A%E7%95%8C%E5%92%8C%E5%AD%A6%E6%9C%AF%E7%95%8C%E7%9A%84%E5%B7%AE%E5%BC%82.pdf">AI on the Edge - Discussion on the Gap Between Industry and Academia</a>" at <a  href="http://valser.org/">VALSE Webinar.</li>
      <p><li> 05/2020, "<a href="https://www.bilibili.com/video/av925692420/">Edge AI: Progress and Future Directions</a>" at <a href="https://www.qbitai.com/">QbitAI</a>.</li></p>
  </div> -->
 <!-- The Publications Section -->
  <div class="w3-container w3-padding-32"" id="publications">
    <h2>Research</h2>
      <p class="w3-left-align" style="line-height:200%">
        I'm interested in <strong>transfer learning</strong> for computer vision. I mainly focus on research topics such as trasferring to downstream tasks, domain adaptation/generalization, continual learning, etc.
      </p>
    <h4> Conference Papers:</h4>

    <ol>

      <p>
      <li><strong>PYRA: Parallel Yielding Re-Activation for Training-Inference Efficient Task Adaptation</strong>
      <br>
      <strong>Yizhe Xiong</strong>, Hui Chen, Tianxiang Hao, Zijia Lin, Jungong Han, Yuesong Zhang, Guoxin Wang, Yongjun Bao, Guiguang Ding
      <br>
      Keywords: Transfer Learning, Parameter-Efficient Fine-Tuning (PEFT), Task Adaptation, Model Pruning, Token Pruning 
      <br>
      <em>ECCV</em> 2024 | <a style="color: #447ec9" href="https://arxiv.org/abs/2403.09192">paper</a>&nbsp;&nbsp;<a style="color: #447ec9" href="https://github.com/Bostoncake/PYRA">GitHub repo</a>
      </p>
	    
      <p>
      <li><strong>Confidence-based Visual Dispersal for Few-shot Unsupervised Domain Adaptation</strong>
      <br>
      <strong>Yizhe Xiong</strong>, Hui Chen, Zijia Lin, Sicheng Zhao, Guiguang Ding
      <br>
      Keywords: Domain Adaptation, Transfer Learning, Few-Shot (Low Shot), Few-Shot Unsupervised Domain Adaptation (FUDA)
      <br>
      <em>ICCV</em> 2023 | <a style="color: #447ec9" href="https://arxiv.org/abs/2309.15575">paper</a>&nbsp;&nbsp;<a style="color: #447ec9" href="https://github.com/Bostoncake/C-VisDiT">GitHub repo</a>
      </p>

      <p>
      <li><strong>Breaking the Stage Barrier: A Novel Single-Stage Approach to Long Context Extension for Large Language Models</strong>
      <br>
      Haoran Lian∗, Junmin Chen∗, Wei Huang∗, <strong>Yizhe Xiong∗</strong>, Wenping Hu*, Guiguang Ding, Hui Chen, Jianwei Niu, Zijia Lin, Fuzheng Zhang, Di Zhang (∗ denotes equal contribution)
      <br>
      Keywords: Large Language Model (LLM), Language Modeling, Long Context Extrapolation
      <br>
      <em>COLING</em> 2025
      </p>

      <p>
      <li><strong>Scaffold-BPE: Enhancing Byte Pair Encoding for Large Language Models with Simple and Effective Scaffold Token Removal</strong>
      <br>
      Haoran Lian, <strong>Yizhe Xiong</strong>, Jianwei Niu, Shasha Mo, Zhenpeng Su, Zijia Lin, Peng Liu, Hui Chen, Guiguang Ding
      <br>
      Keywords: Large Language Model (LLM), Language Modeling, Machine Translation, Byte-Pair Encoding (BPE) 
      <br>
      <em>AAAI</em> 2025
      </p>
	      
    </ol>

    <h4> Others:</h4>

    <ol>

      <p>
      <li><strong>Temporal Scaling Law for Large Language Models</strong>
      <br>
      <strong>Yizhe Xiong</strong>, Xiansheng Chen, Xin Ye, Hui Chen, Zijia Lin, Haoran Lian, Jianwei Niu, Guiguang Ding
      <br>
      Keywords: Large Language Model (LLM), Language Modeling, Scaling Law
      <br>
      <em>Under review</em> | <a style="color: #447ec9" href="https://arxiv.org/abs/2404.17785">paper</a>
      </p>

<!--       <p>
      <li><strong>MaskMoE: Boosting Token-Level Learning via Routing Mask in Mixture-of-Experts</strong>
      <br>
      Zhenpeng Su, Zijia Lin, Xue Bai, Xing Wu, <strong>Yizhe Xiong</strong>, Haoran Lian, Guangyuan Ma, Hui Chen, Guiguang Ding, Wei Zhou, Songlin Hu
      <br>
      Keywords: Large Language Model (LLM), Language Modeling, Mixture of Experts (MoE) 
      <br>
      <em>Under review</em> | <a style="color: #447ec9" href="https://arxiv.org/abs/2407.09816">paper</a>
      </p> -->
	      
    </ol>
  </div>

<!-- The Services Section -->
  <div class="w3-container w3-light-grey w3-padding-32" id="service">
    <h2>Academic Services</h2>
      <!-- <p><li> Area Chair of <a href="https://nips.cc/Conferences/2023/">NeurIPS 2023</a>, <a href="https://icml.cc/Conferences/2023">ICML 2023</a>, <a href="https://nips.cc/Conferences/2022/">NeurIPS 2022</a>, <a href="https://icml.cc/Conferences/2021">ICML 2021</a>, <a href="https://nips.cc/Conferences/2021/">NeurIPS 2021</a>.</p>
      <p><li> Action Editor of <a href="https://jmlr.org/tmlr/">TMLR (Transactions on Machine Learning Research)</a>.</p>
      <p><li> Senior Program Committee Members of <a href="https://ijcai-21.org/">IJCAI 2021</a>, <a href="https://www.ijcai20.org/">IJCAI 2020</a> and <a href="https://www.ijcai19.org/program-committee.html">IJCAI 2019</a>.</p>
      <p><li> Journal Reviewers of <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34">IEEE T-PAMI</a>, <a href="https://www.springer.com/journal/11263">IJCV</a>, <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=83">IEEE T-IP</a>, <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=5962385">IEEE T-NNLS</a>, <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=6046">IEEE T-MM</a>, <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=69">IEEE T-KDE</a>, etc.</p>
      <p><li> Program Committee Members of ICCV 2021, AAAI 2021, ICLR 2021, NeurIPS 2020, ICML 2020, ECCV 2020, CVPR 2020, ICLR 2020, AAAI 2020, ICCV 2019, CVPR 2019, ICLR 2019, AAAI 2019, IJCAI 2018, AAAI 2018, NeurIPS 2018, etc.</p> -->
      <p><li> Reviewer of NeurIPS 2024, IJCAI 2024, ACL Rolling Review 2024, ICLR 2024.</p>
      <p><li> Reviewer of IEEE Transactions on Image Processing.</p>
  </div>

  <!-- The Awards Section -->
  <div class="w3-container w3-padding-32" id="award">
    <h2>Awards</h2>
	  <p><li> 2024, Academic Scholarship, <a href="https://www.thss.tsinghua.edu.cn/">School of Software</a>, <a href="https://www.tsinghua.edu.cn/index.htm">Tsinghua University</a>.</p>
	  <p><li> 2024, First Place and Gold Prize, <a href="https://eval.ai/web/challenges/challenge-page/2314/overview">VISION'24 Data Challenge</a>, <a href="https://eccv.ecva.net/">ECCV 2024</a>.</p>
    	  <p><li> 2023, Academic Scholarship, <a href="https://www.thss.tsinghua.edu.cn/">School of Software</a>, <a href="https://www.tsinghua.edu.cn/index.htm">Tsinghua University</a>.</p>
	  <p><li> 2022, Outstanding Graduate, <a href="https://www.cs.tsinghua.edu.cn/">Department of Computer Science and Technology</a>, <a href="https://www.tsinghua.edu.cn/index.htm">Tsinghua University</a>.</p>
  </div>  

  <div class="w3-light-grey w3-center w3-padding-24">

    Many thanks go to Dr. Yunhe Wang, who shared the source code of <a href="https://github.com/YunheWang/HomePage">his homepage</a>.

  </div>

  <!-- End page content -->
</div>

<script>
// Accordion 
function myAccFunc() {
  var x = document.getElementById("demoAcc");
  if (x.className.indexOf("w3-show") == -1) {
    x.className += " w3-show";
  } else {
    x.className = x.className.replace(" w3-show", "");
  }
}

// Click on the "Jeans" link on page load to open the accordion for demo purposes
document.getElementById("myBtn").click();


// Open and close sidebar
function w3_open() {
  document.getElementById("mySidebar").style.display = "block";
  document.getElementById("myOverlay").style.display = "block";
}
 
function w3_close() {
  document.getElementById("mySidebar").style.display = "none";
  document.getElementById("myOverlay").style.display = "none";
}
</script>

</body>
</html>
